{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8aa0480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout, Conv1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9da7b0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train_data = pd.read_csv('tweets-ext.csv')\n",
    "test_data = pd.read_csv('tweets-test.csv')\n",
    "val_data = pd.read_csv('tweets-valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ae03a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "train_text = train_data['tweet'].tolist()\n",
    "train_labels = train_data['label'].tolist()\n",
    "test_text = test_data['tweet'].tolist()\n",
    "test_labels = test_data['label'].tolist()\n",
    "val_text = val_data['tweet'].tolist()\n",
    "val_labels = val_data['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b96810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_text + test_text + val_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8c17280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text sequences to numerical sequences\n",
    "train_sequences = tokenizer.texts_to_sequences(train_text)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_text)\n",
    "val_sequences = tokenizer.texts_to_sequences(val_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5047506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the sequences to a fixed length\n",
    "max_seq_length = 280\n",
    "train_X = pad_sequences(train_sequences, maxlen=max_seq_length)\n",
    "test_X = pad_sequences(test_sequences, maxlen=max_seq_length)\n",
    "val_X = pad_sequences(val_sequences, maxlen=max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1cdf4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to categorical format\n",
    "num_classes = len(set(train_labels))\n",
    "train_y = to_categorical(train_labels, num_classes=num_classes)\n",
    "test_y = to_categorical(test_labels, num_classes=num_classes)\n",
    "val_y = to_categorical(val_labels, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd6a4597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# Load FastText word embeddings for Marathi\n",
    "embedding_path = 'wiki.mr.bin'\n",
    "embedding_model = fasttext.load_model(embedding_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0db4044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the embedding matrix\n",
    "word_index = tokenizer.word_index\n",
    "num_words = len(word_index) + 1\n",
    "embedding_dim = embedding_model.get_dimension()\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if word in embedding_model:\n",
    "        embedding_matrix[i] = embedding_model[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0a90b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ensemble models\n",
    "num_models = 5\n",
    "model_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a015088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "458/458 [==============================] - 30s 64ms/step - loss: 0.6849 - accuracy: 0.6991 - val_loss: 0.6023 - val_accuracy: 0.7540\n",
      "Epoch 2/10\n",
      "458/458 [==============================] - 27s 59ms/step - loss: 0.5179 - accuracy: 0.7877 - val_loss: 0.5613 - val_accuracy: 0.7733\n",
      "Epoch 3/10\n",
      "458/458 [==============================] - 27s 60ms/step - loss: 0.4092 - accuracy: 0.8374 - val_loss: 0.5400 - val_accuracy: 0.7827\n",
      "Epoch 4/10\n",
      "458/458 [==============================] - 27s 58ms/step - loss: 0.3035 - accuracy: 0.8837 - val_loss: 0.6287 - val_accuracy: 0.7753\n",
      "Epoch 5/10\n",
      "458/458 [==============================] - 27s 59ms/step - loss: 0.1759 - accuracy: 0.9372 - val_loss: 0.7943 - val_accuracy: 0.7500\n",
      "Epoch 6/10\n",
      "458/458 [==============================] - 27s 58ms/step - loss: 0.1136 - accuracy: 0.9594 - val_loss: 0.9600 - val_accuracy: 0.7507\n",
      "Epoch 1/10\n",
      "458/458 [==============================] - 27s 58ms/step - loss: 0.6890 - accuracy: 0.6953 - val_loss: 0.5661 - val_accuracy: 0.7733\n",
      "Epoch 2/10\n",
      "458/458 [==============================] - 27s 59ms/step - loss: 0.5149 - accuracy: 0.7888 - val_loss: 0.5409 - val_accuracy: 0.7800\n",
      "Epoch 3/10\n",
      "458/458 [==============================] - 27s 58ms/step - loss: 0.4085 - accuracy: 0.8361 - val_loss: 0.5551 - val_accuracy: 0.7820\n",
      "Epoch 4/10\n",
      "458/458 [==============================] - 27s 59ms/step - loss: 0.2996 - accuracy: 0.8812 - val_loss: 0.6205 - val_accuracy: 0.7833\n",
      "Epoch 5/10\n",
      "458/458 [==============================] - 29s 63ms/step - loss: 0.1933 - accuracy: 0.9273 - val_loss: 0.6705 - val_accuracy: 0.7747\n",
      "Epoch 1/10\n",
      "458/458 [==============================] - 29s 62ms/step - loss: 0.6831 - accuracy: 0.7012 - val_loss: 0.5867 - val_accuracy: 0.7500\n",
      "Epoch 2/10\n",
      "458/458 [==============================] - 29s 62ms/step - loss: 0.5096 - accuracy: 0.7898 - val_loss: 0.5673 - val_accuracy: 0.7747\n",
      "Epoch 3/10\n",
      "458/458 [==============================] - 27s 58ms/step - loss: 0.4171 - accuracy: 0.8348 - val_loss: 0.5477 - val_accuracy: 0.7893\n",
      "Epoch 4/10\n",
      "458/458 [==============================] - 27s 60ms/step - loss: 0.2996 - accuracy: 0.8847 - val_loss: 0.6306 - val_accuracy: 0.7700\n",
      "Epoch 5/10\n",
      "458/458 [==============================] - 27s 59ms/step - loss: 0.1849 - accuracy: 0.9336 - val_loss: 0.7467 - val_accuracy: 0.7727\n",
      "Epoch 6/10\n",
      "458/458 [==============================] - 27s 60ms/step - loss: 0.1187 - accuracy: 0.9587 - val_loss: 0.8461 - val_accuracy: 0.7627\n",
      "Epoch 1/10\n",
      "458/458 [==============================] - 26s 56ms/step - loss: 0.6859 - accuracy: 0.7002 - val_loss: 0.5696 - val_accuracy: 0.7647\n",
      "Epoch 2/10\n",
      "458/458 [==============================] - 26s 57ms/step - loss: 0.5117 - accuracy: 0.7916 - val_loss: 0.5769 - val_accuracy: 0.7620\n",
      "Epoch 3/10\n",
      "458/458 [==============================] - 26s 57ms/step - loss: 0.4053 - accuracy: 0.8393 - val_loss: 0.5738 - val_accuracy: 0.7820\n",
      "Epoch 4/10\n",
      "458/458 [==============================] - 27s 59ms/step - loss: 0.2926 - accuracy: 0.8912 - val_loss: 0.6691 - val_accuracy: 0.7587\n",
      "Epoch 1/10\n",
      "458/458 [==============================] - 27s 57ms/step - loss: 0.6986 - accuracy: 0.6890 - val_loss: 0.6020 - val_accuracy: 0.7633\n",
      "Epoch 2/10\n",
      "458/458 [==============================] - 26s 57ms/step - loss: 0.5160 - accuracy: 0.7840 - val_loss: 0.5454 - val_accuracy: 0.7767\n",
      "Epoch 3/10\n",
      "458/458 [==============================] - 25s 56ms/step - loss: 0.4153 - accuracy: 0.8316 - val_loss: 0.5458 - val_accuracy: 0.7773\n",
      "Epoch 4/10\n",
      "458/458 [==============================] - 25s 55ms/step - loss: 0.3076 - accuracy: 0.8801 - val_loss: 0.6193 - val_accuracy: 0.7667\n",
      "Epoch 5/10\n",
      "458/458 [==============================] - 26s 57ms/step - loss: 0.1948 - accuracy: 0.9273 - val_loss: 0.8856 - val_accuracy: 0.7427\n"
     ]
    }
   ],
   "source": [
    "# Train individual models\n",
    "for _ in range(num_models):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(num_words, embedding_dim, input_length=max_seq_length, weights=[embedding_matrix], trainable=False))\n",
    "    model.add(Conv1D(128, 5, activation='relu'))\n",
    "    model.add(Conv1D(128, 5, activation='relu'))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model with early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    model.fit(train_X, train_y, validation_data=(val_X, val_y), epochs=10, batch_size=32, callbacks=[early_stopping])\n",
    "    model_list.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "392c1b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 1s 14ms/step\n",
      "47/47 [==============================] - 1s 14ms/step\n",
      "47/47 [==============================] - 1s 14ms/step\n",
      "47/47 [==============================] - 1s 14ms/step\n",
      "47/47 [==============================] - 1s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for validation data\n",
    "val_predictions = []\n",
    "for model in model_list:\n",
    "    predictions = model.predict(val_X)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    val_predictions.append(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff599230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine predictions using majority voting\n",
    "ensemble_val_predictions = np.round(np.mean(val_predictions, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "978dc02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Validation Accuracy: 0.7686666666666667\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the ensemble predictions\n",
    "ensemble_val_accuracy = accuracy_score(np.argmax(val_y, axis=1), ensemble_val_predictions)\n",
    "print(\"Ensemble Validation Accuracy:\", ensemble_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4add0327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 1s 14ms/step\n",
      "71/71 [==============================] - 1s 14ms/step\n",
      "71/71 [==============================] - 1s 15ms/step\n",
      "71/71 [==============================] - 1s 15ms/step\n",
      "71/71 [==============================] - 1s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for test data\n",
    "test_predictions = []\n",
    "for model in model_list:\n",
    "    predictions = model.predict(test_X)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    test_predictions.append(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1701aedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine predictions using majority voting\n",
    "ensemble_test_predictions = np.round(np.mean(test_predictions, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af8f0b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the ensemble predictions\n",
    "ensemble_test_accuracy = accuracy_score(np.argmax(test_y, axis=1), ensemble_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1595ff6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Test Accuracy: 0.7786666666666666\n"
     ]
    }
   ],
   "source": [
    "print(\"Ensemble Test Accuracy:\", ensemble_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e228e25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
