{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6df7de44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout, Conv1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfbcd5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train_data = pd.read_csv('tweets-ext.csv')\n",
    "test_data = pd.read_csv('tweets-test.csv')\n",
    "val_data = pd.read_csv('tweets-valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27610e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "train_text = train_data['tweet'].tolist()\n",
    "train_labels = train_data['label'].tolist()\n",
    "test_text = test_data['tweet'].tolist()\n",
    "test_labels = test_data['label'].tolist()\n",
    "val_text = val_data['tweet'].tolist()\n",
    "val_labels = val_data['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95c438a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data\n",
    "train_text, train_labels = shuffle(train_text, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "442deb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_text + test_text + val_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f131698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text sequences to numerical sequences\n",
    "train_sequences = tokenizer.texts_to_sequences(train_text)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_text)\n",
    "val_sequences = tokenizer.texts_to_sequences(val_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0419d1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the sequences to a fixed length\n",
    "max_seq_length = 280\n",
    "train_X = pad_sequences(train_sequences, maxlen=max_seq_length)\n",
    "test_X = pad_sequences(test_sequences, maxlen=max_seq_length)\n",
    "val_X = pad_sequences(val_sequences, maxlen=max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be52763a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to categorical format\n",
    "num_classes = len(set(train_labels))\n",
    "train_y = to_categorical(train_labels, num_classes=num_classes)\n",
    "test_y = to_categorical(test_labels, num_classes=num_classes)\n",
    "val_y = to_categorical(val_labels, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49f376b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# Load FastText word embeddings for Marathi\n",
    "embedding_path = 'wiki.mr.bin'\n",
    "embedding_model = fasttext.load_model(embedding_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d723aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the embedding matrix\n",
    "word_index = tokenizer.word_index\n",
    "num_words = len(word_index) + 1\n",
    "embedding_dim = embedding_model.get_dimension()\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if word in embedding_model:\n",
    "        embedding_matrix[i] = embedding_model[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9c184fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ensemble models\n",
    "num_models = 5\n",
    "model_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a0c7b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "458/458 [==============================] - 17s 36ms/step - loss: 0.6785 - accuracy: 0.7015 - val_loss: 0.6099 - val_accuracy: 0.7427\n",
      "Epoch 2/10\n",
      "458/458 [==============================] - 16s 35ms/step - loss: 0.4558 - accuracy: 0.8150 - val_loss: 0.5827 - val_accuracy: 0.7720\n",
      "Epoch 3/10\n",
      "458/458 [==============================] - 17s 37ms/step - loss: 0.3098 - accuracy: 0.8798 - val_loss: 0.6167 - val_accuracy: 0.7660\n",
      "Epoch 4/10\n",
      "458/458 [==============================] - 16s 35ms/step - loss: 0.1851 - accuracy: 0.9326 - val_loss: 0.7366 - val_accuracy: 0.7687\n",
      "Epoch 5/10\n",
      "458/458 [==============================] - 17s 36ms/step - loss: 0.1085 - accuracy: 0.9622 - val_loss: 0.8623 - val_accuracy: 0.7660\n",
      "Epoch 1/10\n",
      "458/458 [==============================] - 18s 38ms/step - loss: 0.6910 - accuracy: 0.6938 - val_loss: 0.5443 - val_accuracy: 0.7787\n",
      "Epoch 2/10\n",
      "458/458 [==============================] - 16s 35ms/step - loss: 0.4679 - accuracy: 0.8108 - val_loss: 0.5469 - val_accuracy: 0.7760\n",
      "Epoch 3/10\n",
      "458/458 [==============================] - 16s 35ms/step - loss: 0.3241 - accuracy: 0.8749 - val_loss: 0.5493 - val_accuracy: 0.7860\n",
      "Epoch 4/10\n",
      "458/458 [==============================] - 16s 36ms/step - loss: 0.2002 - accuracy: 0.9292 - val_loss: 0.6880 - val_accuracy: 0.7653\n",
      "Epoch 1/10\n",
      "458/458 [==============================] - 18s 37ms/step - loss: 0.6736 - accuracy: 0.7024 - val_loss: 0.5643 - val_accuracy: 0.7713\n",
      "Epoch 2/10\n",
      "458/458 [==============================] - 17s 37ms/step - loss: 0.4523 - accuracy: 0.8203 - val_loss: 0.5114 - val_accuracy: 0.7887\n",
      "Epoch 3/10\n",
      "458/458 [==============================] - 16s 34ms/step - loss: 0.3106 - accuracy: 0.8810 - val_loss: 0.5480 - val_accuracy: 0.7740\n",
      "Epoch 4/10\n",
      "458/458 [==============================] - 16s 36ms/step - loss: 0.1831 - accuracy: 0.9357 - val_loss: 0.8495 - val_accuracy: 0.7213\n",
      "Epoch 5/10\n",
      "458/458 [==============================] - 16s 35ms/step - loss: 0.1055 - accuracy: 0.9638 - val_loss: 0.7881 - val_accuracy: 0.7793\n",
      "Epoch 1/10\n",
      "458/458 [==============================] - 18s 37ms/step - loss: 0.6766 - accuracy: 0.7022 - val_loss: 0.5853 - val_accuracy: 0.7680\n",
      "Epoch 2/10\n",
      "458/458 [==============================] - 16s 35ms/step - loss: 0.4601 - accuracy: 0.8150 - val_loss: 0.5201 - val_accuracy: 0.7920\n",
      "Epoch 3/10\n",
      "458/458 [==============================] - 16s 34ms/step - loss: 0.3182 - accuracy: 0.8742 - val_loss: 0.5943 - val_accuracy: 0.7727\n",
      "Epoch 4/10\n",
      "458/458 [==============================] - 17s 37ms/step - loss: 0.1897 - accuracy: 0.9294 - val_loss: 0.6153 - val_accuracy: 0.7860\n",
      "Epoch 5/10\n",
      "458/458 [==============================] - 17s 36ms/step - loss: 0.1088 - accuracy: 0.9635 - val_loss: 0.8573 - val_accuracy: 0.7513\n",
      "Epoch 1/10\n",
      "458/458 [==============================] - 17s 37ms/step - loss: 0.6786 - accuracy: 0.7035 - val_loss: 0.5312 - val_accuracy: 0.7860\n",
      "Epoch 2/10\n",
      "458/458 [==============================] - 17s 37ms/step - loss: 0.4454 - accuracy: 0.8194 - val_loss: 0.5468 - val_accuracy: 0.7860\n",
      "Epoch 3/10\n",
      "458/458 [==============================] - 18s 39ms/step - loss: 0.3172 - accuracy: 0.8777 - val_loss: 0.5820 - val_accuracy: 0.7800\n",
      "Epoch 4/10\n",
      "458/458 [==============================] - 18s 40ms/step - loss: 0.1943 - accuracy: 0.9299 - val_loss: 0.6965 - val_accuracy: 0.7540\n"
     ]
    }
   ],
   "source": [
    "# Train individual models\n",
    "for _ in range(num_models):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(num_words, embedding_dim, input_length=max_seq_length, weights=[embedding_matrix], trainable=False))\n",
    "    model.add(Conv1D(128, 5, activation='relu'))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    model.fit(train_X, train_y, validation_data=(val_X, val_y), epochs=10, batch_size=32, callbacks=[early_stopping])\n",
    "    model_list.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1e84aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 1s 12ms/step\n",
      "47/47 [==============================] - 1s 11ms/step\n",
      "47/47 [==============================] - 1s 11ms/step\n",
      "47/47 [==============================] - 1s 11ms/step\n",
      "47/47 [==============================] - 1s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for validation data\n",
    "val_predictions = []\n",
    "for model in model_list:\n",
    "    predictions = model.predict(val_X)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    val_predictions.append(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f7d45c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine predictions using majority voting\n",
    "ensemble_val_predictions = np.round(np.mean(val_predictions, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1287ee4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Validation Accuracy: 0.7753333333333333\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the ensemble predictions\n",
    "ensemble_val_accuracy = accuracy_score(np.argmax(val_y, axis=1), ensemble_val_predictions)\n",
    "print(\"Ensemble Validation Accuracy:\", ensemble_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51b9049e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 1s 11ms/step\n",
      "71/71 [==============================] - 1s 11ms/step\n",
      "71/71 [==============================] - 1s 11ms/step\n",
      "71/71 [==============================] - 1s 11ms/step\n",
      "71/71 [==============================] - 1s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for test data\n",
    "test_predictions = []\n",
    "for model in model_list:\n",
    "    predictions = model.predict(test_X)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    test_predictions.append(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fe5c70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine predictions using majority voting\n",
    "ensemble_test_predictions = np.round(np.mean(test_predictions, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80104d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Test Accuracy: 0.7773333333333333\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the ensemble predictions\n",
    "ensemble_test_accuracy = accuracy_score(np.argmax(test_y, axis=1), ensemble_test_predictions)\n",
    "print(\"Ensemble Test Accuracy:\", ensemble_test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e844051a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
